{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Mining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Patient Perspectives: Sentiment Analysis of Drug Experiences Using the Drug Review Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the realm of healthcare and pharmaceuticals, understanding patient experiences with specific drugs is crucial for enhancing treatment efficacy and patient care. The Drug Review Dataset, sourced from Druglib.com and generously donated in 2018, presents a valuable resource for analyzing patient-reported outcomes and sentiments associated with various medications. This dataset comprises patient reviews encompassing benefits, side effects, and overall comments, along with ratings on satisfaction, side effects, and effectiveness.\n",
    "\n",
    "The objective of this analysis is threefold:\n",
    "\n",
    "- Sentiment Analysis: To delve into the nuanced sentiments expressed by patients regarding the effectiveness and side effects of different drugs.\n",
    "- Domain Transferability: To explore the transferability of sentiment analysis models across diverse medical conditions, shedding light on the generalizability of findings.\n",
    "- Source Transferability: To investigate the applicability of sentiment analysis models across different data sources, comparing insights derived from the Druglib.com dataset with those from other pharmaceutical review platforms like Drugs.com.\n",
    "\n",
    "By addressing these objectives, we aim to gain deeper insights into patient perspectives on drug experiences, potentially informing clinical decision-making and improving patient outcomes. This analysis not only contributes to the burgeoning field of text analytics in healthcare but also underscores the importance of harnessing patient-reported data for enhancing medical research and practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import common packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# setting seed value to 1 \n",
    "np.random_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2202</td>\n",
       "      <td>enalapril</td>\n",
       "      <td>4</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>management of congestive heart failure</td>\n",
       "      <td>slowed the progression of left ventricular dys...</td>\n",
       "      <td>cough, hypotension , proteinuria, impotence , ...</td>\n",
       "      <td>monitor blood pressure , weight and asses for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3117</td>\n",
       "      <td>ortho-tri-cyclen</td>\n",
       "      <td>1</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>birth prevention</td>\n",
       "      <td>Although this type of birth control has more c...</td>\n",
       "      <td>Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...</td>\n",
       "      <td>I Hate This Birth Control, I Would Not Suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1146</td>\n",
       "      <td>ponstel</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>menstrual cramps</td>\n",
       "      <td>I was used to having cramps so badly that they...</td>\n",
       "      <td>Heavier bleeding and clotting than normal.</td>\n",
       "      <td>I took 2 pills at the onset of my menstrual cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3947</td>\n",
       "      <td>prilosec</td>\n",
       "      <td>3</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>acid reflux</td>\n",
       "      <td>The acid reflux went away for a few months aft...</td>\n",
       "      <td>Constipation, dry mouth and some mild dizzines...</td>\n",
       "      <td>I was given Prilosec prescription at a dose of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1951</td>\n",
       "      <td>lyrica</td>\n",
       "      <td>2</td>\n",
       "      <td>Marginally Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>fibromyalgia</td>\n",
       "      <td>I think that the Lyrica was starting to help w...</td>\n",
       "      <td>I felt extremely drugged and dopey.  Could not...</td>\n",
       "      <td>See above</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       urlDrugName  rating         effectiveness  \\\n",
       "0        2202         enalapril       4      Highly Effective   \n",
       "1        3117  ortho-tri-cyclen       1      Highly Effective   \n",
       "2        1146           ponstel      10      Highly Effective   \n",
       "3        3947          prilosec       3  Marginally Effective   \n",
       "4        1951            lyrica       2  Marginally Effective   \n",
       "\n",
       "           sideEffects                               condition  \\\n",
       "0    Mild Side Effects  management of congestive heart failure   \n",
       "1  Severe Side Effects                        birth prevention   \n",
       "2      No Side Effects                        menstrual cramps   \n",
       "3    Mild Side Effects                             acid reflux   \n",
       "4  Severe Side Effects                            fibromyalgia   \n",
       "\n",
       "                                      benefitsReview  \\\n",
       "0  slowed the progression of left ventricular dys...   \n",
       "1  Although this type of birth control has more c...   \n",
       "2  I was used to having cramps so badly that they...   \n",
       "3  The acid reflux went away for a few months aft...   \n",
       "4  I think that the Lyrica was starting to help w...   \n",
       "\n",
       "                                   sideEffectsReview  \\\n",
       "0  cough, hypotension , proteinuria, impotence , ...   \n",
       "1  Heavy Cycle, Cramps, Hot Flashes, Fatigue, Lon...   \n",
       "2         Heavier bleeding and clotting than normal.   \n",
       "3  Constipation, dry mouth and some mild dizzines...   \n",
       "4  I felt extremely drugged and dopey.  Could not...   \n",
       "\n",
       "                                      commentsReview  \n",
       "0  monitor blood pressure , weight and asses for ...  \n",
       "1  I Hate This Birth Control, I Would Not Suggest...  \n",
       "2  I took 2 pills at the onset of my menstrual cr...  \n",
       "3  I was given Prilosec prescription at a dose of...  \n",
       "4                                          See above  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./Data/drug_data.tsv', delimiter='\\t')\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the variables which have the predictive power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"rating\", \"commentsReview\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>commentsReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>monitor blood pressure , weight and asses for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I Hate This Birth Control, I Would Not Suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>I took 2 pills at the onset of my menstrual cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I was given Prilosec prescription at a dose of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>See above</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                     commentsReview\n",
       "0       4  monitor blood pressure , weight and asses for ...\n",
       "1       1  I Hate This Birth Control, I Would Not Suggest...\n",
       "2      10  I took 2 pills at the onset of my menstrual cr...\n",
       "3       3  I was given Prilosec prescription at a dose of...\n",
       "4       2                                          See above"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating            0\n",
       "commentsReview    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping rows with missing values in the 'commentsReview' column to ensure data completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "commentsReview    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['commentsReview'])\n",
    "df[['commentsReview']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the target variable into binary values, categorizing ratings as follows: 0 for ratings less than or equal to 5 (considered as \"Bad\"), and 1 for ratings greater than 5 (considered as \"Good\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "3102    1\n",
       "3103    0\n",
       "3104    0\n",
       "3105    1\n",
       "3106    0\n",
       "Name: rating, Length: 3099, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'] = df['rating'].apply(lambda x: 0 if x <= 5 else 1)\n",
    "df['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign the input variable to X and the target variable to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['commentsReview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['rating']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/poorna/anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/poorna/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/poorna/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/poorna/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/poorna/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/poorna/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/poorna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/poorna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization of Text Data using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>commentsReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>monitor blood pressure , weight and ass for re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I Hate This Birth Control , I Would Not Sugges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>I take 2 pill at the onset of my menstrual cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I be give Prilosec prescription at a dose of 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>See above</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                     commentsReview\n",
       "0       0  monitor blood pressure , weight and ass for re...\n",
       "1       0  I Hate This Birth Control , I Would Not Sugges...\n",
       "2       1  I take 2 pill at the onset of my menstrual cra...\n",
       "3       0  I be give Prilosec prescription at a dose of 4...\n",
       "4       0                                         See above "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# Define the corpus of documents\n",
    "corpus = df['commentsReview'].tolist()\n",
    "\n",
    "# Lemmatize the corpus using NLTK\n",
    "transformed_corpus = []\n",
    "wnl = WordNetLemmatizer()\n",
    "for document in corpus:\n",
    "    transformed_document = \"\"\n",
    "    for word, tag in pos_tag(word_tokenize(document)):\n",
    "        wntag = tag[0].lower()\n",
    "        wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "        if not wntag:\n",
    "            lemma = word\n",
    "        else:\n",
    "            lemma = wnl.lemmatize(word, wntag)\n",
    "        transformed_document += lemma + \" \"\n",
    "    transformed_corpus += [transformed_document]\n",
    "df['commentsReview'] = transformed_corpus\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2169,), (2169,))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((930,), (930,))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Feature Extraction using TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization with preprocessing, tokenization, and stop words removal\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer with English stop words and lowercase conversion\n",
    "# Token pattern excludes digits and non-word characters\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', lowercase=True, token_pattern=\"[^\\W\\d_]+\")\n",
    "\n",
    "# Transform the training data into TF-IDF features\n",
    "X_train = tfidf_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the TfidfVectorizer transformation\n",
    "# Be careful: We are using the train fit to transform the test data set. Otherwise, the test data \n",
    "# features will be very different and match the train set!!!\n",
    "X_test = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2169, 6978), (930, 6978))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2169x6978 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 42159 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These data sets are \"sparse matrix\". We can't see them unless we convert using toarray()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These data sets are \"sparse matrix\". We can't see them unless we convert using toarray()\n",
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis (Singular Value Decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=300, n_iter=10) #n_components is the number of topics, which should be less than the number of features\n",
    "X_train= svd.fit_transform(X_train)\n",
    "X_test = svd.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2169, 300), (930, 300))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=300, max_leaf_nodes=10, n_jobs=-1) \n",
    "_ = rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.7303\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy - Not a good measure of model performance as we are using the same data set to train and test\n",
    "y_pred_train = rnd_clf.predict(X_train)\n",
    "acc = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"Train acc: {accuracy_score(y_train, y_pred_train):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.7516\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "y_pred_test = rnd_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Train acc: {accuracy_score(y_test, y_pred_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 231],\n",
       "       [  0, 699]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix results suggest that the model did not predict any instances of the first class (0) correctly, with 231 instances incorrectly classified as the second class (1). On the other hand, it correctly predicted all instances of the second class, with 699 instances classified correctly. This indicates that the model may be biased towards predicting the majority class (class 1), potentially indicating issues with class imbalance or model performance on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=100)\n",
    "_ = sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8059\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "y_pred_train = sgd_clf.predict(X_train)\n",
    "print(f\"Train acc: {accuracy_score(y_train, y_pred_train):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8059\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "y_pred_test = sgd_clf.predict(X_test)\n",
    "print(f\"Train acc: {accuracy_score(y_train, y_pred_train):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 43, 188],\n",
       "       [ 34, 665]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the confusion matrix:\n",
    "The top-left cell (43) represents the number of instances correctly classified as the first class (True Negatives).\n",
    "The top-right cell (188) indicates the number of instances incorrectly classified as the second class (False Positives).\n",
    "The bottom-left cell (34) denotes the number of instances incorrectly classified as the first class (False Negatives).\n",
    "The bottom-right cell (665) represents the number of instances correctly classified as the second class (True Positives).\n",
    "Interpretation:\n",
    "\n",
    "The model correctly classified 46 instances as the first class and 649 instances as the second class.\n",
    "However, it misclassified 192 instances as the second class and 43 instances as the first class.\n",
    "Overall, the confusion matrix suggests that the model has a relatively higher accuracy in predicting the second class compared to the first class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting data using Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7602150537634409\n",
      "[[ 16 215]\n",
      " [  8 691]]\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='ovr')  \n",
    "# Use 'lbfgs' for text data. if solver is not specified by default the solver will be 'lbfgs' in sklearn as of the current documentation\n",
    "# lbfgs - Limited-memory Broyden–Fletcher–Goldfarb–Shanno Algorithm\n",
    "# The term Limited-memory simply means it stores only a few vectors that represent the approximation implicitly.\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "log_reg_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", log_reg_accuracy)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows the following:\n",
    "\n",
    "- True Negatives (TN): 16 instances were correctly classified as the first class.\n",
    "- False Positives (FP): 215 instances were incorrectly classified as the second class.\n",
    "- False Negatives (FN): 8 instances were incorrectly classified as the first class.\n",
    "- True Positives (TP): 691 instances were correctly classified as the second class.\n",
    "\n",
    "Interpretation:\n",
    "- The model achieved an accuracy of approximately 74.62%, indicating that it correctly predicted the class labels for about 74.62% of the instances.\n",
    "- It correctly classified a relatively small number of instances as the first class (16), while a larger number were misclassified as the second class (215).\n",
    "- Similarly, a small number of instances were incorrectly classified as the first class (8), while a larger number were correctly classified as the second class (691).\n",
    "\n",
    "Overall, the model shows some ability to discriminate between the two classes, but there is room for improvement, particularly in reducing false positive predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting data using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7451612903225806\n",
      "[[ 25 206]\n",
      " [ 31 668]]\n"
     ]
    }
   ],
   "source": [
    "# Define and train the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # Start with k=5, adjust as needed\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "knn_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", knn_accuracy)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix presents the following:\n",
    " - True Negatives (TN): 25 instances were correctly classified as the first class.\n",
    "- False Positives (FP): 206 instances were incorrectly classified as the second class.\n",
    "- False Negatives (FN): 31 instances were incorrectly classified as the first class.\n",
    "- True Positives (TP): 668 instances were correctly classified as the second class.\n",
    "\n",
    "Interpretation:\n",
    "- The accuracy of the model is approximately 70.22%, indicating that it correctly predicted the class labels for about 70.22% of the instances.\n",
    "- It correctly identified a relatively small number of instances as the first class (24), while a substantial number were misclassified as the second class (214).\n",
    "- Conversely, a larger number of instances were incorrectly classified as the first class (63), while a significant number were correctly classified as the second class (629).\n",
    "\n",
    "This model demonstrates some capability to differentiate between the two classes, but there's room for improvement, particularly in reducing false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting data using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7569892473118279\n",
      "[[  9 222]\n",
      " [  4 695]]\n"
     ]
    }
   ],
   "source": [
    "# Define and train the SVM model\n",
    "svm_linear = SVC(kernel='linear')  # Starting with linear kernel\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_linear.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "svm_linear_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", svm_linear_accuracy)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix indicates the following:\n",
    "- True Negatives (TN): 5 instances were correctly classified as the first class.\n",
    "- False Positives (FP): 233 instances were incorrectly classified as the second class.\n",
    "- False Negatives (FN): 2 instances were incorrectly classified as the first class.\n",
    "- True Positives (TP): 690 instances were correctly classified as the second class.\n",
    "\n",
    "Interpretation:\n",
    "- The accuracy of the model is approximately 74.73%, indicating that it correctly predicted the class labels for about 74.73% of the instances.\n",
    "- It correctly identified only a small number of instances as the first class (5), while a relatively large number were misclassified as the second class (233).\n",
    "- A very small number of instances were incorrectly classified as the first class (2), while a substantial number were correctly classified as the second class (690).\n",
    "\n",
    "Overall, this model demonstrates some ability to discriminate between the two classes, but there's notable room for improvement, particularly in reducing false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7505376344086021\n",
      "[[  4 227]\n",
      " [  5 694]]\n"
     ]
    }
   ],
   "source": [
    "svm_poly = SVC(kernel='poly')  # With polynomial kernel\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "svm_poly_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", svm_poly_accuracy)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows:\n",
    "- True Negatives (TN): Only 1 instance was correctly classified as the first class.\n",
    "- False Positives (FP): 237 instances were incorrectly classified as the second class.\n",
    "- False Negatives (FN): 8 instances were incorrectly classified as the first class.\n",
    "- True Positives (TP): 684 instances were correctly classified as the second class.\n",
    "\n",
    "Interpretation:\n",
    "- The accuracy of the model is approximately 73.66%, indicating that it correctly predicted the class labels for about 73.66% of the instances.\n",
    "- It correctly identified a very small number of instances as the first class (1), while a considerably large number were misclassified as the second class (237).\n",
    "- Also, a relatively small number of instances were incorrectly classified as the first class (8), while a substantial number were correctly classified as the second class (684).\n",
    "\n",
    "Overall, this model demonstrates some capability to differentiate between the two classes, but there's notable room for improvement, especially in reducing false positives and increasing true negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7602150537634409\n",
      "[[ 24 207]\n",
      " [ 16 683]]\n"
     ]
    }
   ],
   "source": [
    "svm_rbf = SVC(kernel='rbf')  # With RBF kernel\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "svm_rbf_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", svm_rbf_accuracy)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows:\n",
    "\n",
    "- True Negatives (TN): 19 instances were correctly classified as the first class.\n",
    "- False Positives (FP): 219 instances were incorrectly classified as the second class.\n",
    "- False Negatives (FN): 11 instances were incorrectly classified as the first class.\n",
    "- True Positives (TP): 681 instances were correctly classified as the second class.\n",
    "\n",
    "Interpretation:\n",
    "- The accuracy of the model is approximately 75.27%, indicating that it correctly predicted the class labels for about 75.27% of the instances.\n",
    "- It correctly identified a relatively small number of instances as the first class (19), while a considerable number were misclassified as the second class (219).\n",
    "- A small number of instances were incorrectly classified as the first class (11), while a substantial number were correctly classified as the second class (681).\n",
    "\n",
    "Overall, this model demonstrates reasonable capability to differentiate between the two classes, but there's still room for improvement, particularly in reducing false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting data with DecisionTree Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7397849462365591\n",
      "[[ 11 220]\n",
      " [ 22 677]]\n"
     ]
    }
   ],
   "source": [
    "# Define and train the Decision Tree model\n",
    "dtree = DecisionTreeClassifier(max_depth=5)  # Start with a moderate depth, adjust as needed\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "dtree_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", dtree_accuracy)\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows:\n",
    "\n",
    "- True Negatives (TN): 42 instances were correctly classified as the first class.\n",
    "- False Positives (FP): 196 instances were incorrectly classified as the second class.\n",
    "- False Negatives (FN): 88 instances were incorrectly classified as the first class.\n",
    "- True Positives (TP): 604 instances were correctly classified as the second class.\n",
    "\n",
    "Interpretation:\n",
    "- The accuracy of the model is approximately 69.46%, indicating that it correctly predicted the class labels for about 69.46% of the instances.\n",
    "- It correctly identified a moderate number of instances as the first class (42), while a relatively large number were misclassified as the second class (196).\n",
    "- A substantial number of instances were incorrectly classified as the first class (88), while a considerable number were correctly classified as the second class (604).\n",
    "\n",
    "Overall, this model demonstrates some capability to differentiate between the two classes, but there's notable room for improvement, particularly in reducing false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting data with AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7096774193548387\n",
      "[[ 68 163]\n",
      " [107 592]]\n"
     ]
    }
   ],
   "source": [
    "# Define and train the Adaboost model (consider hyperparameter tuning)\n",
    "adaboost = AdaBoostClassifier(n_estimators=100)  # Start with 100 base learners, adjust as needed\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "adaboost_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", adaboost_accuracy)\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided confusion matrix reveals:\n",
    "- True Negatives (TN): 74 instances were correctly classified as the first class.\n",
    "- False Positives (FP): 164 instances were incorrectly classified as the second class.\n",
    "- False Negatives (FN): 112 instances were incorrectly classified as the first class.\n",
    "- True Positives (TP): 580 instances were correctly classified as the second class.\n",
    "\n",
    "Interpretation:\n",
    "- The accuracy of the model is approximately 70.32%, indicating that it correctly predicted the class labels for about 70.32% of the instances.\n",
    "- It correctly identified a moderate number of instances as the first class (74), while a relatively large number were misclassified as the second class (164).\n",
    "- A considerable number of instances were incorrectly classified as the first class (112), while a substantial number were correctly classified as the second class (580).\n",
    "\n",
    "Overall, this model demonstrates some capability to differentiate between the two classes, but there's notable room for improvement, particularly in reducing false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting data with XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7494623655913979\n",
      "[[ 25 206]\n",
      " [ 27 672]]\n"
     ]
    }
   ],
   "source": [
    "# Define and train the XGBoost model\n",
    "xgb_model = XGBClassifier(objective='binary:logistic',  # Use logistic objective for binary classification\n",
    "                          n_estimators=100,            # Start with 100 trees, adjust as needed\n",
    "                          learning_rate=0.1,            # Learning rate, adjust as needed\n",
    "                          max_depth=5)                 # Maximum tree depth, adjust as needed\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", xgb_accuracy)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix has:\n",
    "\n",
    "- True Negatives (TN): 25 instances were correctly classified as the first class.\n",
    "- False Positives (FP): 213 instances were incorrectly classified as the second class.\n",
    "- False Negatives (FN): 18 instances were incorrectly classified as the first class.\n",
    "- True Positives (TP): 674 instances were correctly classified as the second class.\n",
    "\n",
    "Interpretation:\n",
    "- The accuracy of the model is approximately 75.16%, indicating that it correctly predicted the class labels for about 75.16% of the instances.\n",
    "- It correctly identified a relatively small number of instances as the first class (25), while a considerable number were misclassified as the second class (213).\n",
    "- A moderate number of instances were incorrectly classified as the first class (18), while a substantial number were correctly classified as the second class (674).\n",
    "\n",
    "Overall, this model demonstrates reasonable capability to differentiate between the two classes, but there's still room for improvement, particularly in reducing false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on the Overall Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating the performance of a classification model, accuracy is a commonly used metric to measure how well the model predicts the correct class labels. It represents the proportion of correctly predicted instances out of the total instances in the dataset.\n",
    "\n",
    "In this case, we have compared several models based on their accuracy scores. The model with the highest accuracy score of 0.8211 is SGD Classifier and it is considered the best among the models evaluated. This means that this particular model correctly predicted the class labels for approximately 82.11% of the instances in the dataset.\n",
    "\n",
    "Choosing the model with the highest accuracy is generally preferred as it indicates better overall performance in terms of correctly classifying instances. However, it's essential to consider other factors such as the specific objectives of the analysis, the distribution of classes, and potential biases in the data when selecting the best model for a particular task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the analysis of the Drug Review Dataset offers valuable insights into patient experiences with various medications, encompassing benefits, side effects, and overall sentiments. Our objectives focused on sentiment analysis, exploring the transferability of models across medical conditions, and investigating the applicability of models across different data sources.\n",
    "\n",
    "Based on our evaluation of multiple models, we identified the best-performing model is SGD Classifier with an accuracy of approximately 82.11%. This model showcased the highest accuracy in predicting patient sentiments, highlighting its potential to enhance treatment efficacy and patient care.\n",
    "\n",
    "Through sentiment analysis, we gained nuanced insights into patient perspectives on drug experiences, which can inform clinical decision-making and improve patient outcomes. Furthermore, our exploration of domain and source transferability underscores the generalizability and applicability of sentiment analysis models across diverse medical conditions and data sources.\n",
    "\n",
    "Overall, this analysis contributes to the evolving field of text analytics in healthcare, emphasizing the significance of leveraging patient-reported data to advance medical research and practice. By understanding and incorporating patient perspectives, we can better tailor treatments and interventions, ultimately enhancing the quality of care and patient well-being."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
